{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e301b6c5",
   "metadata": {},
   "source": [
    "## Terminal Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e96dc947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in ./venv/lib/python3.6/site-packages (4.63.0)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.6/site-packages (from tqdm) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.6/site-packages (from importlib-resources->tqdm) (3.6.0)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.2-cp36-cp36m-macosx_10_13_x86_64.whl (7.2 MB)\n",
      "Requirement already satisfied: joblib>=0.11 in ./venv/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./venv/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./venv/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-0.24.2 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas\n",
    "#!pip install pyspark\n",
    "#!pip install nltk\n",
    "!pip install tqdm\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6ee27",
   "metadata": {},
   "source": [
    "## Imports & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "07d524a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from dateutil.parser import parse\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils import class_weight\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd0155",
   "metadata": {},
   "source": [
    "## Global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adf66ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES_TO_IGNORE = ['bolig', 'abonnement']\n",
    "SITES_TO_IGNORE = ['kundeservice.adressa.no']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa65e5c",
   "metadata": {},
   "source": [
    "## Contextual Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f131809",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_article_folder = \"home/lemeiz/content_refine/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55deec0",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57d2df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saken oppdateres. Det er Trøndelag politidistrikt som klokken 15.50 melder om at to barn er observert over tunnelåpningen Frøyatunnelen på Frøya-siden. Ifølge Twitter-meldingen er det ingen sikring på stedet og fare for at barna kan falle ned i veien. Politipatruljen fant ingen barn da de kom til stedet, kun fotspor, opplyser politiet på Twitter klokken 16.00. Nå advarer politet mot å leke i dette området. - Dette er ingen lekeplass, skriver politiet.\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(path_to_article_folder, os.listdir(path_to_article_folder)[0]), 'r', encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    content_raw = json.loads(line)\n",
    "    dict_content = {}\n",
    "    for key in content_raw:\n",
    "        if key == 'fields':\n",
    "            for json_field in content_raw['fields']:\n",
    "                value = json_field['value']\n",
    "                if json_field['field'] == 'body':\n",
    "                    value = ' '.join(value)\n",
    "                dict_content[json_field['field']] = value\n",
    "        dict_content[key] = content_raw[key]\n",
    "    \n",
    "    print(dict_content['body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bb7b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_to_dict(line:str) -> dict:\n",
    "    content_raw = json.loads(line)\n",
    "    dict_content = {}\n",
    "    for key in content_raw:\n",
    "        if key == 'fields':\n",
    "            for json_field in content_raw['fields']:\n",
    "                value = json_field['value']\n",
    "                if json_field['field'] == 'body':\n",
    "                    value = ' '.join(value)\n",
    "                dict_content[json_field['field']] = value\n",
    "        else:\n",
    "            dict_content[key] = content_raw[key]\n",
    "    \n",
    "    return dict_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a120cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_information_parse(line:str) -> dict:\n",
    "    def unique_list_if_str(value):\n",
    "        if type(value) == list:\n",
    "            return value\n",
    "        else:\n",
    "            return [value]\n",
    "        \n",
    "        \n",
    "    #content_raw = parse_json_to_dict(line)\n",
    "    content_raw = defaultdict(str, parse_json_to_dict(line))\n",
    "    \n",
    "    publishtime = content_raw['publishtime'] if content_raw['publishtime'] != '' else content_raw['createtime'] \n",
    "    #Converting to unix timestamp in miliseconds\n",
    "    publishtime_ts = int(parse(publishtime).timestamp()) * 1000\n",
    "    \n",
    "    author_1st = content_raw['author'][0] if type(content_raw['author']) == list else content_raw['author']\n",
    "    \n",
    "    if type(content_raw['heading']) == list:\n",
    "        heading = set(content_raw['heading']) #Set to remove repeated phrases\n",
    "    else:\n",
    "        heading = [content_raw['heading']]\n",
    "    \n",
    "    textual_highlights = \"{} | {} | {} | {}\".format(content_raw['title'], \n",
    "                                                            content_raw['teaser'], \n",
    "                                                            '. '.join(heading),\n",
    "                                                            content_raw['body']) \\\n",
    "                        .replace(u'\\xad','').replace('\"', '')\n",
    "    \n",
    "    new_content = {'id': content_raw['id'],\n",
    "                   'url': content_raw['url'],\n",
    "                   'site': unique_list_if_str(content_raw['og-site-name'])[0],\n",
    "                   'adressa-access': content_raw['adressa-access'], #(free, subscriber)\n",
    "                   'author_1st':  author_1st if author_1st != '' else '', #3777 unique                  \n",
    "                   'publishtime': publishtime,\n",
    "                   'created_at_ts': publishtime_ts,\n",
    "                   'text_highlights': textual_highlights, \n",
    "                   #Extracted using NLP techniques (by Adressa)\n",
    "                   'concepts': ','.join(unique_list_if_str(content_raw['kw-concept'])), #98895 unique\n",
    "                   'entities': ','.join(unique_list_if_str(content_raw['kw-entity'])), #150214 unique\n",
    "                   'locations': ','.join(unique_list_if_str(content_raw['kw-location'])), #5533 unique\n",
    "                   'persons': ','.join(unique_list_if_str(content_raw['kw-person'])), #53535 unique\n",
    "                   #Categories and keywords tagged by the journalists of Adresseavisen and may be of variable quality (label)\n",
    "                   'category0': content_raw['category0'], #39 unique\n",
    "                   'category1': content_raw['category1'] if 'category1' in content_raw else '', #126 unique\n",
    "                   'category2': content_raw['category2'] if 'category2' in content_raw else '', #75 unique\n",
    "                   'keywords': content_raw['keywords'], #6489 unique\n",
    "                  }\n",
    "\n",
    "        \n",
    "    return new_content\n",
    "\n",
    "with open(os.path.join(path_to_article_folder, os.listdir(path_to_article_folder)[0]), 'r', encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    x = article_information_parse(line)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c26a329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x['locations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b2ca1dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6',\n",
       " 'url': 'http://www.adressa.no/nyheter/sortrondelag/2016/03/02/Dette-er-ingen-lekeplass-12228016.ece',\n",
       " 'site': 'adressa.no',\n",
       " 'adressa-access': 'free',\n",
       " 'author_1st': 'pål solberg',\n",
       " 'publishtime': '2016-03-02T14:58:31.000Z',\n",
       " 'created_at_ts': 1456930711000,\n",
       " 'text_highlights': '- Dette er ingen lekeplass | To barn ble observert over tunnelåpningen på Frøyatunnelen. Politiet fant bare fotspor etter barna da de kom til stedet. | - Dette er ingen lekeplass -adressa.no | Saken oppdateres. Det er Trøndelag politidistrikt som klokken 15.50 melder om at to barn er observert over tunnelåpningen Frøyatunnelen på Frøya-siden. Ifølge Twitter-meldingen er det ingen sikring på stedet og fare for at barna kan falle ned i veien. Politipatruljen fant ingen barn da de kom til stedet, kun fotspor, opplyser politiet på Twitter klokken 16.00. Nå advarer politet mot å leke i dette området. - Dette er ingen lekeplass, skriver politiet.',\n",
       " 'concepts': 'politiet,barn',\n",
       " 'entities': 'twitter,frøyatunnelen',\n",
       " 'locations': 'frøya,trøndelag',\n",
       " 'persons': '',\n",
       " 'category0': 'nyheter',\n",
       " 'category1': 'nyheter|sortrondelag',\n",
       " 'category2': '',\n",
       " 'keywords': 'utenriks,innenriks,trondheim,E6,midtbyen,bybrann,bilulykker'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_content_file(fp:str):\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            for line in f:\n",
    "                if line.strip()=='null':\n",
    "                    return None\n",
    "                else:\n",
    "                    content=article_information_parse(line)\n",
    "                return content\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "parse_content_file(os.path.join(path_to_article_folder, os.listdir(path_to_article_folder)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7088ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5207/74886 [00:06<01:32, 755.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-e9cac2f6f437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_article_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-111-e9cac2f6f437>\u001b[0m in \u001b[0;36mload_files\u001b[0;34m(rel_path, file_list)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_content_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0marticle_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-d8fc12f545fe>\u001b[0m in \u001b[0;36mparse_content_file\u001b[0;34m(fp)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'null'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_files(rel_path, file_list=None) -> pd.DataFrame:\n",
    "    if not file_list:\n",
    "        file_list = os.listdir(rel_path)\n",
    "    \n",
    "    article_data = []\n",
    "    \n",
    "    for idx, filename in enumerate(tqdm(file_list)):\n",
    "        fp = os.path.join(rel_path, filename)\n",
    "        file_content = parse_content_file(fp)\n",
    "        if file_content:\n",
    "            article_data.append(file_content)\n",
    "            \n",
    "    print(f'# Files processed       : {len(file_list)}')\n",
    "    print(f'# Files parsed          : {len(article_data)}')\n",
    "    print(f'# Files rejected (empty): {len(file_list) - file_content}')\n",
    "    \n",
    "    return article_data\n",
    "    \n",
    "    \n",
    "load_files(path_to_article_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f7f9d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_folder(rel_path):\n",
    "    articles_list = os.listdir(rel_path)\n",
    "    articles = load_files(rel_path, articles_list)\n",
    "    \n",
    "    news_df = pd.DataFrame([art for art in articles])\n",
    "    news_df = news_df[(~news_df['category0'].isin(CATEGORIES_TO_IGNORE)) & (~news_df['site'].astype(str).isin(SITES_TO_IGNORE))]\n",
    "\n",
    "    news_df.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "    return news_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
