"""
In this file I create some global variables.
They are of some different types, and each type has its own dictionary.
To get access from outside the file, do "import globals", then e.g. globals.learning_params['epochs']
"""

# Parameters defining the actual learning.
learning_params = {
    "learning_rate": 0.05,
    "epochs": 40,
    "batch_size": 4096,  # must be even if using a generator
    "seed": 42,
}

# Parameters defining the properties of the data. These are just random things for now.
data_params = {
    'title_size': 10,  # Max number of words in the title of the news document
    'body_size': 50,  # Max number of words in the body of the news article
    'no_categories': 41,  # The total number of categories available. I don't know what this is...# Todo
    'no_sub_categories': 128,  # The total number of sub-categories available. I don't know what this is...# Todo
    'vocabulary_size': 20000,  # Total number of different word in the vocabulary
    'max_no_documents_in_user_profile': 5,  # The number of previous documents used by the user encoder.
    # 5 in the picture in the paper, but parameterized here for good practice
    # Embedder_params
    'min_count': 20,
    'window': 5,
    # History_values
    'min_history_size': 5,
    'min_interactions': 5,
    # Location_values
    # 'location_embedding_vector_size': 100,
    'max_locations_per_article': 10,  # 10 leaves 0.4%. to be cropped. Reduces locations by 0.8% The distribution can be
    # found by the following command:
    #                       article_df.locations_encoded.apply(literal_eval).apply(len).value_counts(True).sort_index()
}

data_params['article_size'] = data_params['title_size'] + data_params['body_size'] + 2
# Hyper-parameters defining the model
model_params = {
    'word_embedding_dim': 10,  # Dimensionality of the word embedding
    'attention_hidden_dim': 5,  # The dimensionality used in the ChineseAttention model. Size of embedding of q
    'dropout_probability': .2,  # Dropout in convolutions of the news-encoder
    'no_conv_filters': 10,  # Number of convolutional filters used in the document encoding
    'conv_window_size': 5,  # Window-size for the convolutions used in the document encoding
    'conv_activation_function': 'relu',  # Activation-func for convolutions in news encoder.
    # Any text recognized by Keras works here: relu, selu, whatever.
    'dense_activation_function': 'relu',  # Activation-function to use in the dense layer.
    'category_embedding_dim': 10,  # Dimensions used to embed the (sub-)categories internally in the news-encoder
    'similarity_function': 'dot', # The similarity function for scoring the different categories, can also be cosine


}

data_params['vector_size'] = model_params['word_embedding_dim'] # Only used by tokenizer_embedder # todo: change & del

country_codes = {
    'af': 'afghanistan',
    'al': 'albania',
    'dz': 'algerie',
    'as': 'samoa',
    'ad': 'andorra',
    'ao': 'angola',
    'ai': 'anguilla',
    'aq': 'antarktika',
    'ag': 'barbuda',
    'ar': 'argentina',
    'am': 'armenia',
    'aw': 'aruba',
    'az': 'aserbajdsjan',
    'au': 'australia',
    'bs': 'bahamas',
    'bh': 'bahrain',
    'bd': 'bangladesh',
    'bb': 'barbados',
    'be': 'belgia',
    'bz': 'belize',
    'bj': 'benin',
    'bm': 'bermuda',
    'bt': 'bhutan',
    'bo': 'bolivia',
    'bq': 'bonaire',
    'ba': 'bosnia-hercegovina',
    'bw': 'botswana',
    'bv': 'bouvetøya',
    'br': 'brasil',
    'bn': 'brunei',
    'bg': 'bulgaria',
    'bf': 'burkina',
    'bi': 'burundi',
    'ca': 'canada',
    'ky': 'caymanøyene',
    'cl': 'chile',
    'cx': 'christmasøya',
    'co': 'colombia',
    'ck': 'cookøyene',
    'cr': 'costa',
    'cu': 'cuba',
    'cw': 'curaçao',
    'dk': 'danmark',
    'ae': 'emirater',
    'tf': 'sørterritorier',
    'ps': 'palestina',
    'do': 'dominikanske',
    'cf': 'sentralafrikanske',
    'io': 'indiahavet',
    'dj': 'djibouti',
    'dm': 'dominica',
    'ec': 'ecuador',
    'eg': 'egypt',
    'gq': 'ekvatorial-guinea',
    'ci': 'elfenbenskysten',
    'sv': 'salvador',
    'er': 'eritrea',
    'ee': 'estland',
    'et': 'etiopia',
    'fk': 'falklandsøyene',
    'fj': 'fiji',
    'ph': 'filippinene',
    'fi': 'finland',
    'fr': 'frankrike',
    'gf': 'guyana',
    'pf': 'polynesia',
    'fo': 'færøyene',
    'ga': 'gabon',
    'gm': 'gambia',
    'ge': 'georgia',
    'gh': 'ghana',
    'gi': 'gibraltar',
    'gd': 'grenada',
    'gl': 'grønnland',
    'gp': 'guadeloupe',
    'gu': 'guam',
    'gt': 'guatemala',
    'gg': 'guernsey',
    'gn': 'guinea',
    'gw': 'guinea-bissau',
    'gy': 'guyana',
    'ht': 'haiti',
    'hm': 'mcdonaldøyene',
    'gr': 'hellas',
    'hn': 'honduras',
    'hk': 'kong',
    'by': 'hviterussland',
    'in': 'india',
    'id': 'indonesia',
    'iq': 'irak',
    'ir': 'iran',
    'ie': 'irland',
    'is': 'island',
    'il': 'israel',
    'it': 'italia',
    'jm': 'jamaica',
    'jp': 'japan',
    'ye': 'jemen',
    'je': 'jersey',
    'vi': 'jomfruøyene',
    'vg': 'jomfruøyene',
    'jo': 'jordan',
    'kh': 'kambodsja',
    'cm': 'kamerun',
    'cv': 'verde',
    'kz': 'kasakhstan',
    'ke': 'kenya',
    'cn': 'kina',
    'kg': 'kirgisistan',
    'ki': 'kiribati',
    'cc': 'kokosøyene',
    'km': 'komorene',
    'cd': 'kongo',
    'cg': 'kongo',
    'hr': 'kroatia',
    'kw': 'kuwait',
    'cy': 'kypros',
    'la': 'laos',
    'lv': 'latvia',
    'ls': 'lesotho',
    'lb': 'libanon',
    'lr': 'liberia',
    'ly': 'libya',
    'li': 'liechtenstein',
    'lt': 'litauen',
    'lu': 'luxembourg',
    'mo': 'macao',
    'mg': 'madagaskar',
    'mk': 'makedonia,',
    'mw': 'malawi',
    'my': 'malaysia',
    'mv': 'maldivene',
    'ml': 'mali',
    'mt': 'malta',
    'im': 'man',
    'ma': 'marokko',
    'mh': 'marshalløyene',
    'mq': 'martinique',
    'mr': 'mauritania',
    'mu': 'mauritius',
    'yt': 'mayotte',
    'mx': 'mexico',
    'fm': 'mikronesiaføderasjonen',
    'md': 'moldova',
    'mc': 'monaco',
    'mn': 'mongolia',
    'me': 'montenegro',
    'ms': 'montserrat',
    'mz': 'mosambik',
    'mm': 'myanmar',
    'na': 'namibia',
    'nr': 'nauru',
    'np': 'nepal',
    'nl': 'nederland',
    'nz': 'zealand',
    'ni': 'nicaragua',
    'ne': 'niger',
    'ng': 'nigeria',
    'nu': 'niue',
    'kp': 'nord-korea',
    'mp': 'nord-marianene',
    'nf': 'norfolkøya',
    'no': 'norge',
    'nc': 'ny-caledonia',
    'om': 'oman',
    'pk': 'pakistan',
    'pw': 'palau',
    'pa': 'panama',
    'pg': 'ny-guinea',
    'py': 'paraguay',
    'pe': 'peru',
    'pn': 'pitcairnøyene',
    'pl': 'polen',
    'pt': 'portugal',
    'pr': 'puerto',
    'qa': 'qatar',
    're': 'réunion',
    'ro': 'romania',
    'ru': 'russland',
    'rw': 'rwanda',
    'bl': 'saint-barthélemy',
    'sh': 'helena',
    'kn': 'kitts',
    'lc': 'lucia',
    'mf': 'saint-martin',
    'pm': 'saint-pierre',
    'vc': 'grenadinene',
    'sb': 'salomonøyene',
    'ws': 'samoa',
    'sm': 'marino',
    'st': 'principe',
    'sa': 'saudi-arabia',
    'sn': 'senegal',
    'rs': 'serbia',
    'sc': 'seychellene',
    'sl': 'leone',
    'sg': 'singapore',
    'sx': 'maarten',
    'sk': 'slovakia',
    'si': 'slovenia',
    'so': 'somalia',
    'es': 'spania',
    'lk': 'lanka',
    'gb': 'storbritannia',
    'sd': 'sudan',
    'sr': 'surinam',
    'sj': 'svalbard',
    'ch': 'sveits',
    'se': 'sverige',
    'sz': 'swaziland',
    'sy': 'syria',
    'za': 'sør-afrika',
    'gs': 'sør-georgia',
    'kr': 'sør-korea',
    'ss': 'sør-sudan',
    'tj': 'tadsjikistan',
    'tw': 'taiwan',
    'tz': 'tanzania',
    'th': 'thailand',
    'tg': 'togo',
    'tk': 'tokelau',
    'to': 'tonga',
    'tt': 'trinidad',
    'td': 'tsjad',
    'cz': 'tsjekkia',
    'tn': 'tunisia',
    'tm': 'turkmenistan',
    'tc': 'caicosøyene',
    'tv': 'tuvalu',
    'tr': 'tyrkia',
    'de': 'tyskland',
    'ug': 'uganda',
    'ua': 'ukraina',
    'hu': 'ungarn',
    'uy': 'uruguay',
    'us': 'usa',
    'um': 'usas',
    'uz': 'usbekistan',
    'vu': 'vanuatu',
    'va': 'vatikanstaten',
    've': 'venezuela',
    'eh': 'vest-sahara',
    'vn': 'vietnam',
    'wf': 'wallis',
    'zm': 'zambia',
    'zw': 'zimbabwe',
    'at': 'østerrike',
    'tl': 'øst-timor',
    'ax': 'åland',
    'uk': 'storbritannia'
}


# Merge everything into one dicts -- the model_params.
# This is the dict I will then send to "weights and biases" for documentation of each run
model_params.update(learning_params)
model_params.update(data_params)
